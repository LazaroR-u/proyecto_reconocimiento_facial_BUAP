{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d1ee4a",
   "metadata": {},
   "source": [
    "# MODELO IDENTIFICADOR DE ATRIBUTOS EN IMAGENES\n",
    "Lázaro R. Díaz Lievano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114a07d",
   "metadata": {},
   "source": [
    "En este notebook se define y entrena un modelo para identificar atributos en imagenes como parte del curso de Redes Neuronales de la FCFM de la BUAP, se utiliza la base de datos de CelebA, la cual se puede encontrar en kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d2f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Dropout,Activation,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4902f",
   "metadata": {},
   "source": [
    "## Cargando los datos: lista de atributos e imagenes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c91a2",
   "metadata": {},
   "source": [
    "La lista de atributos inicialmente es un archivo de texto lleno de datos en forma de tabla, donde -1 se refiere a Falso y 1 a Verdadero, trabajar con este tipo de dato en este formato es tedioso por lo que lo mejor es convertirlo a un CSV, es decir, un archivo separado por comas, para ello reemplazamos los espacios por comas y podemos omitir trabajar con los encabezados que si bien para nosotros son importantes, para la red neuronal le es indiferente porque no tiene una idea de que signifique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad81e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping: 202599\n",
      "\n",
      "skipping headers: 5_o_Clock_Shadow Arched_Eyebrows Attractive Bags_Under_Eyes Bald Bangs Big_Lips Big_Nose Black_Hair Blond_Hair Blurry Brown_Hair Bushy_Eyebrows Chubby Double_Chin Eyeglasses Goatee Gray_Hair Heavy_Makeup High_Cheekbones Male Mouth_Slightly_Open Mustache Narrow_Eyes No_Beard Oval_Face Pale_Skin Pointy_Nose Receding_Hairline Rosy_Cheeks Sideburns Smiling Straight_Hair Wavy_Hair Wearing_Earrings Wearing_Hat Wearing_Lipstick Wearing_Necklace Wearing_Necktie Young \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cargamos la lista de atributos\n",
    "atributos = 'C:/Users/Lazaro Diaz/RNA_otono2022/Reconocimiento facial/list_attr_celeba.txt'\n",
    "atributos_modificado = 'C:/Users/Lazaro Diaz/RNA_otono2022/Reconocimiento facial/list_attr_celeba_modificado.txt' \n",
    "#archivo en blanco donde se guardara la nueva lista\n",
    "\n",
    "with open(atributos, 'r') as f:\n",
    "    print(\"skipping: \" + f.readline())\n",
    "    print(\"skipping headers: \" + f.readline())\n",
    "    with open(atributos_modificado, 'w') as newf:\n",
    "        for line in f:\n",
    "            new_line = ' '.join(line.split())\n",
    "            newf.write(new_line)\n",
    "            newf.write('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46def2",
   "metadata": {},
   "source": [
    "Ahora definimos unos parametros de la red. Estos valores son arbitrarios, pero por cuestiones de tiempo es mejor iniciar con pocas epocas y asegurarnos que la red esté aprendiendo, conforme vayamos consiguiendo resultados aceptables podemos luego aumentar las epocas, por el contrario, si la red no aprende o es muy deficiente podemos aumentar el numero de batch_size, cambiar el optimizador, el learning rate o por supuesto, asegurarnos de que los datos con los que se entrena esten correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f5cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 40\n",
    "optimizer = 'rmsprop'\n",
    "ih, iw = 192, 192 #tamaño de la imagen\n",
    "input_shape = (ih, iw,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f8cc44",
   "metadata": {},
   "source": [
    "## Uniendo los dos tipos de dato en uno solo  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a74a9",
   "metadata": {},
   "source": [
    "Una vez que ya terminamos con los datos de atributos y con las imagenes, podemos unirlas, cada lista de atributos con su correspondiente imagen, de esta forma la red asociará los atributos con la imagen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c4c0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define el dataframe \n",
    "atributos = 'C:/Users/Lazaro Diaz/RNA_otono2022/Reconocimiento facial/list_attr_celeba_modificado.txt'\n",
    "df = pd.read_csv(atributos, sep=' ',  header=None)\n",
    "\n",
    "#Se separan las imagenes y sus atributos para poder modificar los valores de -1 a 0, luego se vuelven a unir\n",
    "files = tf.data.Dataset.from_tensor_slices(df[0])\n",
    "attributes= tf.data.Dataset.from_tensor_slices(df.iloc[:,1:].to_numpy().astype('int64')).map(lambda x: ((x+1)/2))\n",
    "data = tf.data.Dataset.zip((files,attributes))\n",
    "\n",
    "\n",
    "ruta_imagenes = 'C:/Users/Lazaro Diaz/RNA_otono2022/Reconocimiento facial/img_align_celeba/'\n",
    "\n",
    "def process_file(file_name, attributes):\n",
    "    image = tf.io.read_file(ruta_imagenes + file_name)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [ih,iw])\n",
    "    image /= 255.0\n",
    "    return image, attributes\n",
    "\n",
    "imagen_etiquetada = data.map(process_file).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dda3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50d38ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se definen parámetros de la red y se dividen los datos en datos de entrenamiento y prueba\n",
    "\n",
    "num_train = int(len(df)*0.7) #70% de los datos serán datos de prueba\n",
    "num_test =len(df) - num_train #30% de los datos se usarán para evaluar la red.\n",
    "\n",
    "epochs_steps = num_train // batch_size\n",
    "test_steps = num_test // batch_size\n",
    "\n",
    "data_train = imagen_etiquetada.take(num_train)\n",
    "data_test = imagen_etiquetada.skip(num_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ef93b",
   "metadata": {},
   "source": [
    "## Estructura de la red neuronal para identificar atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8530b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Primera capa Convolucional\n",
    "model.add(Conv2D(40, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Segunda capa Convolucional\n",
    "model.add(Conv2D(80, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Tercera capa Convolucional\n",
    "model.add(Conv2D(120, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Cuarta capa Plana o Densa\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Capa de salida, aqui hay 40 neuronas correspondientes a cada atributo, \n",
    "#si la neurona se activa significa que la imagen posee el atributo\n",
    "model.add(Dense(40))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "332d6344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 190, 190, 40)      1120      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 190, 190, 40)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 95, 95, 40)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 93, 93, 80)        28880     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 93, 93, 80)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 46, 46, 80)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 44, 44, 120)       86520     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 44, 44, 120)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 120)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 58080)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3717184   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                2600      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 40)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,836,304\n",
      "Trainable params: 3,836,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f999e7",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62fef926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5065/5065 [==============================] - ETA: 0s - loss: 0.2780 - binary_accuracy: 0.8796WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1519 batches). You may need to use the repeat() function when building your dataset.\n",
      "5065/5065 [==============================] - 30227s 6s/step - loss: 0.2780 - binary_accuracy: 0.8796\n",
      "Epoch 2/10\n",
      "5065/5065 [==============================] - 8505s 2s/step - loss: 0.2466 - binary_accuracy: 0.8927\n",
      "Epoch 3/10\n",
      "5065/5065 [==============================] - 8326s 2s/step - loss: 0.2392 - binary_accuracy: 0.8960\n",
      "Epoch 4/10\n",
      "5065/5065 [==============================] - 8467s 2s/step - loss: 0.2351 - binary_accuracy: 0.8979\n",
      "Epoch 5/10\n",
      "5065/5065 [==============================] - 9207s 2s/step - loss: 0.2334 - binary_accuracy: 0.8988\n",
      "Epoch 6/10\n",
      "5065/5065 [==============================] - 8808s 2s/step - loss: 0.2340 - binary_accuracy: 0.8987\n",
      "Epoch 7/10\n",
      "5065/5065 [==============================] - 8989s 2s/step - loss: 0.2357 - binary_accuracy: 0.8981\n",
      "Epoch 8/10\n",
      "5065/5065 [==============================] - 9207s 2s/step - loss: 0.2384 - binary_accuracy: 0.8970\n",
      "Epoch 9/10\n",
      "5065/5065 [==============================] - 8948s 2s/step - loss: 0.2416 - binary_accuracy: 0.8956\n",
      "Epoch 10/10\n",
      "5065/5065 [==============================] - 8582s 2s/step - loss: 0.2450 - binary_accuracy: 0.8945\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(data_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=data_test,\n",
    "    validation_steps=test_steps,\n",
    "    #callbacks=[WandbCallback()\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c55457",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rna_attrib.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74661e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755adaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
